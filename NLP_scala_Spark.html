<!DOCTYPE html>
<html>
<head>
  <meta name="databricks-html-version" content="1">
<title>NLP_scala_Spark - Databricks</title>

<meta charset="utf-8">
<meta name="google" content="notranslate">
<meta name="robots" content="nofollow">
<meta http-equiv="Content-Language" content="en">
<meta http-equiv="Content-Type" content="text/html; charset=UTF8">

<link rel="stylesheet" type="text/css" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/785e573cb9325327d1468f16a431e6d7119df032dd9ffcc16d4a909725271125/css/main.css">
<link rel="stylesheet" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/785e573cb9325327d1468f16a431e6d7119df032dd9ffcc16d4a909725271125/css/print.css" media="print">
<link rel="icon" type="image/png" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/785e573cb9325327d1468f16a431e6d7119df032dd9ffcc16d4a909725271125/img/favicon.ico"/>
<script>window.settings = {"enableNotebookNotifications":true,"enableSshKeyUI":false,"defaultInteractivePricePerDBU":0.4,"enableClusterMetricsUI":true,"enableOnDemandClusterType":true,"enableAutoCompleteAsYouType":[],"devTierName":"Community Edition","enableJobsPrefetching":true,"workspaceFeaturedLinks":[{"linkURI":"https://docs.databricks.com/index.html","displayName":"Documentation","icon":"question"},{"linkURI":"https://docs.databricks.com/release-notes/product/index.html","displayName":"Release Notes","icon":"code"},{"linkURI":"https://docs.databricks.com/spark/latest/training/index.html","displayName":"Training & Tutorials","icon":"graduation-cap"}],"enableReservoirTableUI":false,"enableClearStateFeature":true,"dbcForumURL":"http://forums.databricks.com/","enableProtoClusterInfoDeltaPublisher":true,"enableAttachExistingCluster":true,"resetJobListOnConnect":true,"serverlessDefaultSparkVersion":"latest-stable-scala2.11","maxCustomTags":45,"serverlessDefaultMaxWorkers":20,"enableInstanceProfilesUIInJobs":true,"nodeInfo":{"node_types":[{"support_ssh":false,"spark_heap_memory":4800,"instance_type_id":"r3.2xlarge","spark_core_oversubscription_factor":8.0,"node_type_id":"dev-tier-node","description":"Community Optimized","support_cluster_tags":false,"container_memory_mb":6000,"node_instance_type":{"instance_type_id":"r3.2xlarge","provider":"AWS","local_disk_size_gb":160,"compute_units":26.0,"number_of_ips":14,"local_disks":1,"reserved_compute_units":3.64,"gpus":0,"memory_mb":62464,"num_cores":8,"local_disk_type":"AHCI","max_attachable_disks":0,"supported_disk_types":[{"ebs_volume_type":"GENERAL_PURPOSE_SSD"},{"ebs_volume_type":"THROUGHPUT_OPTIMIZED_HDD"}],"reserved_memory_mb":4800},"memory_mb":6144,"is_hidden":false,"category":"Community Edition","num_cores":0.88,"support_port_forwarding":false,"support_ebs_volumes":false,"is_deprecated":false}],"default_node_type_id":"dev-tier-node"},"sqlAclsDisabledMap":{"spark.databricks.acl.enabled":"false","spark.databricks.acl.sqlOnly":"false"},"enableDatabaseSupportClusterChoice":true,"enableClusterAcls":true,"notebookRevisionVisibilityHorizon":999999,"serverlessClusterProductName":"Serverless Pool","showS3TableImportOption":true,"maxEbsVolumesPerInstance":10,"isAdmin":true,"deltaProcessingBatchSize":1000,"timerUpdateQueueLength":100,"sqlAclsEnabledMap":{"spark.databricks.acl.enabled":"true","spark.databricks.acl.sqlOnly":"true"},"enableLargeResultDownload":true,"maxElasticDiskCapacityGB":5000,"serverlessDefaultMinWorkers":2,"zoneInfos":[{"id":"us-west-2c","isDefault":true},{"id":"us-west-2b","isDefault":false},{"id":"us-west-2a","isDefault":false}],"enableCustomSpotPricingUIByTier":false,"serverlessClustersEnabled":false,"enableFindAndReplace":true,"disallowUrlImportExceptFromDocs":false,"defaultStandardClusterModel":{"cluster_name":"","node_type_id":"dev-tier-node","spark_version":"3.5.x-scala2.11","num_workers":0,"aws_attributes":{"first_on_demand":0,"availability":"ON_DEMAND","zone_id":"us-west-2c","spot_bid_price_percent":100},"autotermination_minutes":120,"default_tags":{"Vendor":"Databricks","Creator":"marissaldouglas@gmail.com","ClusterName":null,"ClusterId":"<Generated after creation>"}},"enableEBSVolumesUIForJobs":true,"enablePublishNotebooks":true,"enableBitbucketCloud":true,"createTableInNotebookS3Link":{"url":"https://docs.databricks.com/_static/notebooks/data-import/s3.html","displayName":"S3","workspaceFileName":"S3 Example"},"sanitizeHtmlResult":true,"enableJobAclsConfig":false,"enableFullTextSearch":false,"enableElasticSparkUI":false,"enableNewClustersCreate":true,"clusters":true,"allowRunOnPendingClusters":true,"useAutoscalingByDefault":false,"enableAzureToolbar":false,"fileStoreBase":"FileStore","enableEmailInAzure":false,"enableRLibraries":true,"enableTableAclsConfig":false,"enableSshKeyUIInJobs":true,"enableDetachAndAttachSubMenu":true,"configurableSparkOptionsSpec":[{"keyPattern":"spark\\.kryo(\\.[^\\.]+)+","valuePattern":".*","keyPatternDisplay":"spark.kryo.*","valuePatternDisplay":"*","description":"Configuration options for Kryo serialization"},{"keyPattern":"spark\\.io\\.compression\\.codec","valuePattern":"(lzf|snappy|org\\.apache\\.spark\\.io\\.LZFCompressionCodec|org\\.apache\\.spark\\.io\\.SnappyCompressionCodec)","keyPatternDisplay":"spark.io.compression.codec","valuePatternDisplay":"snappy|lzf","description":"The codec used to compress internal data such as RDD partitions, broadcast variables and shuffle outputs."},{"keyPattern":"spark\\.serializer","valuePattern":"(org\\.apache\\.spark\\.serializer\\.JavaSerializer|org\\.apache\\.spark\\.serializer\\.KryoSerializer)","keyPatternDisplay":"spark.serializer","valuePatternDisplay":"org.apache.spark.serializer.JavaSerializer|org.apache.spark.serializer.KryoSerializer","description":"Class to use for serializing objects that will be sent over the network or need to be cached in serialized form."},{"keyPattern":"spark\\.rdd\\.compress","valuePattern":"(true|false)","keyPatternDisplay":"spark.rdd.compress","valuePatternDisplay":"true|false","description":"Whether to compress serialized RDD partitions (e.g. for StorageLevel.MEMORY_ONLY_SER). Can save substantial space at the cost of some extra CPU time."},{"keyPattern":"spark\\.speculation","valuePattern":"(true|false)","keyPatternDisplay":"spark.speculation","valuePatternDisplay":"true|false","description":"Whether to use speculation (recommended off for streaming)"},{"keyPattern":"spark\\.es(\\.[^\\.]+)+","valuePattern":".*","keyPatternDisplay":"spark.es.*","valuePatternDisplay":"*","description":"Configuration options for ElasticSearch"},{"keyPattern":"es(\\.([^\\.]+))+","valuePattern":".*","keyPatternDisplay":"es.*","valuePatternDisplay":"*","description":"Configuration options for ElasticSearch"},{"keyPattern":"spark\\.(storage|shuffle)\\.memoryFraction","valuePattern":"0?\\.0*([1-9])([0-9])*","keyPatternDisplay":"spark.(storage|shuffle).memoryFraction","valuePatternDisplay":"(0.0,1.0)","description":"Fraction of Java heap to use for Spark's shuffle or storage"},{"keyPattern":"spark\\.streaming\\.backpressure\\.enabled","valuePattern":"(true|false)","keyPatternDisplay":"spark.streaming.backpressure.enabled","valuePatternDisplay":"true|false","description":"Enables or disables Spark Streaming's internal backpressure mechanism (since 1.5). This enables the Spark Streaming to control the receiving rate based on the current batch scheduling delays and processing times so that the system receives only as fast as the system can process. Internally, this dynamically sets the maximum receiving rate of receivers. This rate is upper bounded by the values `spark.streaming.receiver.maxRate` and `spark.streaming.kafka.maxRatePerPartition` if they are set."},{"keyPattern":"spark\\.streaming\\.receiver\\.maxRate","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.receiver.maxRate","valuePatternDisplay":"numeric","description":"Maximum rate (number of records per second) at which each receiver will receive data. Effectively, each stream will consume at most this number of records per second. Setting this configuration to 0 or a negative number will put no limit on the rate. See the deployment guide in the Spark Streaming programing guide for mode details."},{"keyPattern":"spark\\.streaming\\.kafka\\.maxRatePerPartition","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.kafka.maxRatePerPartition","valuePatternDisplay":"numeric","description":"Maximum rate (number of records per second) at which data will be read from each Kafka partition when using the Kafka direct stream API introduced in Spark 1.3. See the Kafka Integration guide for more details."},{"keyPattern":"spark\\.streaming\\.kafka\\.maxRetries","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.kafka.maxRetries","valuePatternDisplay":"numeric","description":"Maximum number of consecutive retries the driver will make in order to find the latest offsets on the leader of each partition (a default value of 1 means that the driver will make a maximum of 2 attempts). Only applies to the Kafka direct stream API introduced in Spark 1.3."},{"keyPattern":"spark\\.streaming\\.ui\\.retainedBatches","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.ui.retainedBatches","valuePatternDisplay":"numeric","description":"How many batches the Spark Streaming UI and status APIs remember before garbage collecting."}],"enableReactNotebookComments":true,"enableAdminPasswordReset":false,"checkBeforeAddingAadUser":false,"enableResetPassword":true,"maxClusterTagValueLength":255,"enableJobsSparkUpgrade":true,"createTableInNotebookDBFSLink":{"url":"https://docs.databricks.com/_static/notebooks/data-import/dbfs.html","displayName":"DBFS","workspaceFileName":"DBFS Example"},"perClusterAutoterminationEnabled":false,"enableNotebookCommandNumbers":true,"allowStyleInSanitizedHtml":true,"sparkVersions":[{"key":"1.6.3-db2-hadoop2-scala2.10","displayName":"Spark 1.6.3-db2 (Hadoop 2, Scala 2.10)","packageLabel":"spark-image-aba860a0ffce4f3471fb14aefdcb1d768ac66a53a5ad884c48745ef98aeb9d67","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":[]},{"key":"3.3.x-gpu-scala2.11","displayName":"3.3 (includes Apache Spark 2.2.0, GPU, Scala 2.11)","packageLabel":"spark-image-280a8d41cd338f5b48d43eb87622c542c6e6584c430f6d3afe8f3401b9607cb9","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"2.1.1-db5-scala2.11","displayName":"Spark 2.1.1-db5 (Scala 2.11)","packageLabel":"spark-image-08d9fc1551087e0876236f19640c4a83116b1649f15137427d21c9056656e80e","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"1.6.x-ubuntu15.10","displayName":"Spark 1.6.x (Hadoop 1)","packageLabel":"spark-image-8cea23fb9094e174bf5815d79009f4a8e383eb86cf2909cf6c6434ed8da2a16a","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"3.3.x-scala2.10","displayName":"3.3 (includes Apache Spark 2.2.0, Scala 2.10)","packageLabel":"spark-image-dd410c68e21c3c563ad6128d35705b605d70530124d55aff1dd12d7e15adfa20","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"1.4.x-ubuntu15.10","displayName":"Spark 1.4.1 (Hadoop 1, deprecated)","packageLabel":"spark-image-f710650fb8aaade8e4e812368ea87c45cd8cd0b5e6894ca6c94f3354e8daa6dc","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"2.2.x-scala2.11","displayName":"3.0 (includes Apache Spark 2.2.0, Scala 2.11)","packageLabel":"spark-image-67ab3a06d1e83d5b60df7063245eb419a2e9fe329aeeb7e7d9713332c669bb17","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"2.1.1-db6-scala2.10","displayName":"Spark 2.1.1-db6 (Scala 2.10)","packageLabel":"spark-image-177f3f02a6a3432d30068332dc857b9161345bdd2ee8a2d2de05bb05cb4b0f4c","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"2.1.0-db2-scala2.11","displayName":"Spark 2.1.0-db2 (Scala 2.11)","packageLabel":"spark-image-267c4490a3ab8a39acdbbd9f1d36f6decdecebf013e30dd677faff50f1d9cf8b","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"4.0.x-scala2.11","displayName":"4.0 beta (Scala 2.11)","packageLabel":"spark-image-952b87d1275ecbc989729594efb02f7d4d1a67851a81d77729e0051822de3a42","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION","SUPPORTS_TABLE_ACLS"]},{"key":"2.1.x-gpu-scala2.11","displayName":"Spark 2.1 (Auto-updating, GPU, Scala 2.11 experimental)","packageLabel":"spark-image-d613235f93e0f29838beb2079a958c02a192ed67a502192bc67a8a5f2fb37f35","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":[]},{"key":"2.0.0-ubuntu15.10-scala2.10","displayName":"Spark 2.0.0 (Scala 2.10)","packageLabel":"spark-image-073c1b52ace74f251fae2680624a0d8d184a8b57096d1c21c5ce56c29be6a37a","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"latest-stable-gpu-scala2.11","displayName":"Latest stable (3.5, GPU, Scala 2.11)","packageLabel":"spark-image-150ea14c3136dac53b46f721799aac3d93e75d91e4035aa535220bea607510c2","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"3.4.x-scala2.11","displayName":"3.4 (includes Apache Spark 2.2.0, Scala 2.11)","packageLabel":"spark-image-a5615cb1adf0d2305f2b93188c6720174ec3e782d100fcbfa96ff870392861df","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"2.0.2-db3-scala2.10","displayName":"Spark 2.0.2-db3 (Scala 2.10)","packageLabel":"spark-image-584091dedb690de20e8cf22d9e02fdcce1281edda99eedb441a418d50e28088f","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"3.2.x-scala2.10","displayName":"3.2 (includes Apache Spark 2.2.0, Scala 2.10)","packageLabel":"spark-image-557788bea0eea16bbf7a8ba13ace07e64dd7fc86270bd5cea086097fe886431f","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":[]},{"key":"latest-experimental-scala2.10","displayName":"Latest experimental (Scala 2.10)","packageLabel":"spark-image-ec81b6840af02ee2321dd8dfe2587437bbcddf024d4ae287f326a98fac406a6c","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"4.0.x-gpu-scala2.11","displayName":"4.0 beta (GPU, Scala 2.11)","packageLabel":"spark-image-894806c9b31f3c0f03348ed22a72d911b7109022830558934513decce984cb66","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":[]},{"key":"2.1.0-db1-scala2.11","displayName":"Spark 2.1.0-db1 (Scala 2.11)","packageLabel":"spark-image-e8ad5b72cf0f899dcf2b4720c1f572ab0e87a311d6113b943b4e1d4a7edb77eb","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"2.1.1-db4-scala2.11","displayName":"Spark 2.1.1-db4 (Scala 2.11)","packageLabel":"spark-image-52bca0ca866e3f4243d3820a783abf3b9b3b553edf234abef14b892657ceaca9","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"latest-rc-scala2.11","displayName":"Latest RC (4.0, Scala 2.11)","packageLabel":"spark-image-952b87d1275ecbc989729594efb02f7d4d1a67851a81d77729e0051822de3a42","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION","SUPPORTS_TABLE_ACLS"]},{"key":"latest-stable-scala2.11","displayName":"Latest stable (3.5, Scala 2.11)","packageLabel":"spark-image-edea2f4129c468cb4b9642796b9933911d5e3723e9a97553ff5b0fbb7121d114","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"2.1.0-db2-scala2.10","displayName":"Spark 2.1.0-db2 (Scala 2.10)","packageLabel":"spark-image-a2ca4f6b58c95f78dca91b1340305ab3fe32673bd894da2fa8e1dc8a9f8d0478","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"1.6.x-ubuntu15.10-hadoop1","displayName":"Spark 1.6.x (Hadoop 1)","packageLabel":"spark-image-8cea23fb9094e174bf5815d79009f4a8e383eb86cf2909cf6c6434ed8da2a16a","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"2.0.2-db4-scala2.11","displayName":"Spark 2.0.2-db4 (Scala 2.11)","packageLabel":"spark-image-7dbc7583e8271765b8a1508cb9e832768e35489bbde2c4c790bc6766aee2fd7f","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":[]},{"key":"1.6.1-ubuntu15.10-hadoop1","displayName":"Spark 1.6.1 (Hadoop 1)","packageLabel":"spark-image-21d1cac181b7b8856dd1b4214a3a734f95b5289089349db9d9c926cb87d843db","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"2.0.x-gpu-scala2.11","displayName":"Spark 2.0 (Auto-updating, GPU, Scala 2.11 experimental)","packageLabel":"spark-image-968b89f1d0ec32e1ee4dacd04838cae25ef44370a441224177a37980d539d83a","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":[]},{"key":"1.6.2-ubuntu15.10-hadoop1","displayName":"Spark 1.6.2 (Hadoop 1)","packageLabel":"spark-image-8cea23fb9094e174bf5815d79009f4a8e383eb86cf2909cf6c6434ed8da2a16a","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"next-major-version-scala2.11","displayName":"Next major version (4.0 snapshot, Scala 2.11)","packageLabel":"spark-image-c7103f67105405c5963a5d160edf5baac88fdbfb74af06c8122e7d63b667b2f9","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"1.6.3-db1-hadoop2-scala2.10","displayName":"Spark 1.6.3-db1 (Hadoop 2, Scala 2.10)","packageLabel":"spark-image-eaa8d9b990015a14e032fb2e2e15be0b8d5af9627cd01d855df728b67969d5d9","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"1.6.3-db2-hadoop1-scala2.10","displayName":"Spark 1.6.3-db2 (Hadoop 1, Scala 2.10)","packageLabel":"spark-image-14112ea0645bea94333a571a150819ce85573cf5541167d905b7e6588645cf3b","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":[]},{"key":"3.5.x-scala2.10","displayName":"3.5 (includes Apache Spark 2.2.1, Scala 2.10)","packageLabel":"spark-image-38fb6f623fbe4e652be9d58083e85e6982c9b79b5052e71d534b6e3ac267a355","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"1.6.2-ubuntu15.10-hadoop2","displayName":"Spark 1.6.2 (Hadoop 2)","packageLabel":"spark-image-161245e66d887cd775e23286a54bab0b146143e1289f25bd1732beac454a1561","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"1.6.1-ubuntu15.10-hadoop2","displayName":"Spark 1.6.1 (Hadoop 2)","packageLabel":"spark-image-4cafdf8bc6cba8edad12f441e3b3f0a8ea27da35c896bc8290e16b41fd15496a","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"2.0.2-db2-scala2.10","displayName":"Spark 2.0.2-db2 (Scala 2.10)","packageLabel":"spark-image-36d48f22cca7a907538e07df71847dd22aaf84a852c2eeea2dcefe24c681602f","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"2.0.x-ubuntu15.10-scala2.11","displayName":"Spark 2.0 (Ubuntu 15.10, Scala 2.11, deprecated)","packageLabel":"spark-image-8e1c50d626a52eac5a6c8129e09ae206ba9890f4523775f77af4ad6d99a64c44","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"2.0.x-scala2.10","displayName":"Spark 2.0 (Auto-updating, Scala 2.10)","packageLabel":"spark-image-859e88079f97f58d50e25163b39a1943d1eeac0b6939c5a65faba986477e311a","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":[]},{"key":"2.1.1-db4-scala2.10","displayName":"Spark 2.1.1-db4 (Scala 2.10)","packageLabel":"spark-image-c7c0224de396cd1563addc1ae4bca6ba823780b6babe6c3729ddf73008f29ba4","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"latest-rc-scala2.10","displayName":"Latest RC (Scala 2.10)","packageLabel":"spark-image-ec81b6840af02ee2321dd8dfe2587437bbcddf024d4ae287f326a98fac406a6c","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"latest-stable-scala2.10","displayName":"Latest stable (3.5, Scala 2.10)","packageLabel":"spark-image-38fb6f623fbe4e652be9d58083e85e6982c9b79b5052e71d534b6e3ac267a355","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"2.0.2-db1-scala2.11","displayName":"Spark 2.0.2-db1 (Scala 2.11)","packageLabel":"spark-image-c2d623f03dd44097493c01aa54a941fc31978ebe6d759b36c75b716b2ff6ab9c","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"2.0.2-db4-scala2.10","displayName":"Spark 2.0.2-db4 (Scala 2.10)","packageLabel":"spark-image-859e88079f97f58d50e25163b39a1943d1eeac0b6939c5a65faba986477e311a","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":[]},{"key":"2.1.1-db5-scala2.10","displayName":"Spark 2.1.1-db5 (Scala 2.10)","packageLabel":"spark-image-74133df2c13950431298d1cab3e865c191d83ac33648a8590495c52fc644c654","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"3.4.x-gpu-scala2.11","displayName":"3.4 (includes Apache Spark 2.2.0, GPU, Scala 2.11)","packageLabel":"spark-image-613a129fcaa93423a4de06407c9f93e341ed5c6b02d69179d2703c8bb47e2b99","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":[]},{"key":"1.5.x-ubuntu15.10","displayName":"Spark 1.5.2 (Hadoop 1, deprecated)","packageLabel":"spark-image-c9d2a8abf41f157a4acc6d52bc721090346f6fea2de356f3a66e388f54481698","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"latest-experimental-gpu-scala2.11","displayName":"Latest experimental (4.1 snapshot, GPU, Scala 2.11)","packageLabel":"spark-image-1935e698db219ca92cc82e7f8d5a67bf436e4afddc7a8f3a1b52c799853c71dd","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"2.2.x-scala2.10","displayName":"3.0 (includes Apache Spark 2.2.0, Scala 2.10)","packageLabel":"spark-image-d549f2d4a523994ecdf37e531b51d5ec7d8be51534bb0ca5322eaad28ba8f557","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"3.0.x-scala2.11","displayName":"3.0 (includes Apache Spark 2.2.0, Scala 2.11)","packageLabel":"spark-image-67ab3a06d1e83d5b60df7063245eb419a2e9fe329aeeb7e7d9713332c669bb17","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"2.0.x-scala2.11","displayName":"Spark 2.0 (Auto-updating, Scala 2.11)","packageLabel":"spark-image-7dbc7583e8271765b8a1508cb9e832768e35489bbde2c4c790bc6766aee2fd7f","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":[]},{"key":"2.1.x-scala2.10","displayName":"Spark 2.1 (Auto-updating, Scala 2.10)","packageLabel":"spark-image-177f3f02a6a3432d30068332dc857b9161345bdd2ee8a2d2de05bb05cb4b0f4c","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"3.1.x-scala2.11","displayName":"3.1 (includes Apache Spark 2.2.0, Scala 2.11)","packageLabel":"spark-image-241fa8b78ee6343242b1756b18076270894385ff40a81172a6fb5eadf66155d3","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"2.1.0-db3-scala2.10","displayName":"Spark 2.1.0-db3 (Scala 2.10)","packageLabel":"spark-image-25a17d070af155f10c4232dcc6248e36a2eb48c24f8d4fc00f34041b86bd1626","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"2.0.2-db2-scala2.11","displayName":"Spark 2.0.2-db2 (Scala 2.11)","packageLabel":"spark-image-4fa852ba378e97815083b96c9cada7b962a513ec23554a5fc849f7f1dd8c065a","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"3.1.x-scala2.10","displayName":"3.1 (includes Apache Spark 2.2.0, Scala 2.10)","packageLabel":"spark-image-7efac6b9a8f2da59cb4f6d0caac46cfcb3f1ebf64c8073498c42d0360f846714","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"3.3.x-scala2.11","displayName":"3.3 (includes Apache Spark 2.2.0, Scala 2.11)","packageLabel":"spark-image-73a161da0570b3f51c8eb238602af2f5561789ea80b25c69a48691fc84e2d974","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"next-major-version-gpu-scala2.11","displayName":"Next major version (4.0 snapshot, GPU, Scala 2.11)","packageLabel":"spark-image-bed05a09fd05efc4936b9d982431e1bbdef6ba1efae2a7779f2db84bbbee541f","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"3.5.x-gpu-scala2.11","displayName":"3.5 (includes Apache Spark 2.2.1, GPU, Scala 2.11)","packageLabel":"spark-image-150ea14c3136dac53b46f721799aac3d93e75d91e4035aa535220bea607510c2","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":[]},{"key":"1.3.x-ubuntu15.10","displayName":"Spark 1.3.0 (Hadoop 1, deprecated)","packageLabel":"spark-image-40d2842670bc3dc178b14042501847d76171437ccf70613fa397a7a24c48b912","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"2.0.1-db1-scala2.11","displayName":"Spark 2.0.1-db1 (Scala 2.11)","packageLabel":"spark-image-10ab19f634bbfdb860446c326a9f76dc25bfa87de6403b980566279142a289ea","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"2.0.2-db3-scala2.11","displayName":"Spark 2.0.2-db3 (Scala 2.11)","packageLabel":"spark-image-7fd7aaa89d55692e429115ae7eac3b1a1dc4de705d50510995f34306b39c2397","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"2.1.1-db6-scala2.11","displayName":"Spark 2.1.1-db6 (Scala 2.11)","packageLabel":"spark-image-fdad9ef557700d7a8b6bde86feccbcc3c71d1acdc838b0fd299bd19956b1076e","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"1.6.3-db1-hadoop1-scala2.10","displayName":"Spark 1.6.3-db1 (Hadoop 1, Scala 2.10)","packageLabel":"spark-image-d50af1032799546b8ccbeeb76889a20c819ebc2a0e68ea20920cb30d3895d3ae","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"2.0.2-db1-scala2.10","displayName":"Spark 2.0.2-db1 (Scala 2.10)","packageLabel":"spark-image-654bdd6e9bad70079491987d853b4b7abf3b736fff099701501acaabe0e75c41","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"2.0.x-ubuntu15.10","displayName":"Spark 2.0 (Ubuntu 15.10, Scala 2.10, deprecated)","packageLabel":"spark-image-a659f3909d51b38d297b20532fc807ecf708cfb7440ce9b090c406ab0c1e4b7e","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"3.5.x-scala2.11","displayName":"3.5 (includes Apache Spark 2.2.1, Scala 2.11)","packageLabel":"spark-image-edea2f4129c468cb4b9642796b9933911d5e3723e9a97553ff5b0fbb7121d114","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"latest-experimental-scala2.11","displayName":"Latest experimental (4.1 snapshot, Scala 2.11)","packageLabel":"spark-image-61078fa9d04a4d345f459f4cbf2170bc51f432ea79913277f234c203fcca7a6f","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION","SUPPORTS_TABLE_ACLS"]},{"key":"3.2.x-scala2.11","displayName":"3.2 (includes Apache Spark 2.2.0, Scala 2.11)","packageLabel":"spark-image-5537926238bc55cb6cd76ee0f0789511349abead3781c4780721a845f34b5d4e","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":[]},{"key":"2.0.1-db1-scala2.10","displayName":"Spark 2.0.1-db1 (Scala 2.10)","packageLabel":"spark-image-5a13c2db3091986a4e7363006cc185c5b1108c7761ef5d0218506cf2e6643840","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"2.1.x-scala2.11","displayName":"Spark 2.1 (Auto-updating, Scala 2.11)","packageLabel":"spark-image-fdad9ef557700d7a8b6bde86feccbcc3c71d1acdc838b0fd299bd19956b1076e","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"2.1.0-db1-scala2.10","displayName":"Spark 2.1.0-db1 (Scala 2.10)","packageLabel":"spark-image-f0ab82a5deb7908e0d159e9af066ba05fb56e1edb35bdad41b7ad2fd62a9b546","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"3.0.x-scala2.10","displayName":"3.0 (includes Apache Spark 2.2.0, Scala 2.10)","packageLabel":"spark-image-d549f2d4a523994ecdf37e531b51d5ec7d8be51534bb0ca5322eaad28ba8f557","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"1.6.0-ubuntu15.10","displayName":"Spark 1.6.0 (Hadoop 1)","packageLabel":"spark-image-10ef758029b8c7e19cd7f4fb52fff9180d75db92ca071bd94c47f3c1171a7cb5","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"1.6.x-ubuntu15.10-hadoop2","displayName":"Spark 1.6.x (Hadoop 2)","packageLabel":"spark-image-161245e66d887cd775e23286a54bab0b146143e1289f25bd1732beac454a1561","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"2.0.0-ubuntu15.10-scala2.11","displayName":"Spark 2.0.0 (Scala 2.11)","packageLabel":"spark-image-b4ec141e751f201399f8358a82efee202560f7ed05e1a04a2ae8778f6324b909","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"2.1.0-db3-scala2.11","displayName":"Spark 2.1.0-db3 (Scala 2.11)","packageLabel":"spark-image-ccbc6b73f158e2001fc1fb8c827bfdde425d8bd6d65cb7b3269784c28bb72c16","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"latest-rc-gpu-scala2.11","displayName":"Latest RC (4.0 GPU, Scala 2.11)","packageLabel":"spark-image-894806c9b31f3c0f03348ed22a72d911b7109022830558934513decce984cb66","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"3.4.x-scala2.10","displayName":"3.4 (includes Apache Spark 2.2.0, Scala 2.10)","packageLabel":"spark-image-b768d65de82a89fbfabff8ec1d2f279ced527c0ec05e83c3ae0c206d2e97edc0","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]}],"enablePresentationMode":false,"enableClearStateAndRunAll":true,"enableTableAclsByTier":false,"enableRestrictedClusterCreation":true,"enableFeedback":true,"enableClusterAutoScaling":false,"enableUserVisibleDefaultTags":true,"defaultNumWorkers":0,"serverContinuationTimeoutMillis":10000,"jobsUnreachableThresholdMillis":60000,"driverStderrFilePrefix":"stderr","enableNotebookRefresh":false,"createTableInNotebookImportedFileLink":{"url":"https://docs.databricks.com/_static/notebooks/data-import/imported-file.html","displayName":"Imported File","workspaceFileName":"Imported File Example"},"accountsOwnerUrl":"https://accounts.cloud.databricks.com/registration.html#login","tableAclsDisabledMap":{"spark.databricks.acl.dfAclsEnabled":"false"},"driverStdoutFilePrefix":"stdout","showDbuPricing":true,"databricksDocsBaseHostname":"docs.databricks.com","defaultNodeTypeToPricingUnitsMap":{"r3.2xlarge":2,"i3.4xlarge":4,"class-node":1,"m4.2xlarge":1.5,"r4.xlarge":1,"m4.4xlarge":3,"Standard_DS5_v2":3,"Standard_D2s_v3":0.5,"Standard_DS14":4,"r4.16xlarge":16,"Standard_DS11":0.5,"p2.8xlarge":16,"m4.10xlarge":8,"Standard_D8s_v3":1.5,"Standard_E32s_v3":8,"Standard_DS3":0.75,"Standard_DS2_v2":0.5,"r3.8xlarge":8,"r4.4xlarge":4,"dev-tier-node":1,"Standard_L8s":2,"Standard_E4s_v3":1,"Standard_D3_v2":0.75,"Standard_DS15_v2":8,"Standard_D16s_v3":3,"Standard_D5_v2":3,"Standard_E8s_v3":2,"c3.8xlarge":4,"Standard_E2s_v3":0.5,"Standard_DS3_v2":0.75,"r3.4xlarge":4,"Standard_DS4":1.5,"i2.4xlarge":6,"m4.xlarge":0.75,"r4.8xlarge":8,"Standard_H16":4,"Standard_DS14_v2":4,"r4.large":0.5,"Standard_DS12":1,"development-node":1,"i2.2xlarge":3,"g2.8xlarge":6,"i3.large":0.75,"memory-optimized":1,"m4.large":0.4,"Standard_F4s":0.5,"p2.16xlarge":24,"i3.8xlarge":8,"i3.16xlarge":16,"Standard_DS12_v2":1,"Standard_L32s":8,"Standard_D4s_v3":0.75,"Standard_DS13":2,"Standard_DS11_v2":0.5,"Standard_DS13_v2":2,"c3.2xlarge":1,"Standard_L4s":1,"Standard_F16s":2,"c4.2xlarge":1,"Standard_L16s":4,"i2.xlarge":1.5,"Standard_DS2":0.5,"compute-optimized":1,"c4.4xlarge":2,"Standard_D2_v2":0.5,"i3.2xlarge":2,"Standard_E16s_v3":4,"Standard_F8s":1,"c3.4xlarge":2,"g2.2xlarge":1.5,"p2.xlarge":2,"m4.16xlarge":12,"Standard_DS4_v2":1.5,"c4.8xlarge":4,"i3.xlarge":1,"r3.xlarge":1,"r4.2xlarge":2,"i2.8xlarge":12},"tableFilesBaseFolder":"/tables","enableSparkDocsSearch":true,"sparkHistoryServerEnabled":true,"enableEBSVolumesUI":false,"homePageWelcomeMessage":"Welcome to ","metastoreServiceRowLimit":1000000,"enableIPythonImportExport":true,"enableClusterTagsUIForJobs":true,"enableClusterTagsUI":false,"enableNotebookHistoryDiffing":true,"branch":"2.62.884","accountsLimit":3,"enableSparkEnvironmentVariables":true,"enableX509Authentication":false,"useAADLogin":false,"enableStructuredStreamingNbOptimizations":true,"enableNotebookGitBranching":true,"local":false,"enableNotebookLazyRenderWrapper":false,"enableClusterAutoScalingForJobs":true,"enableStrongPassword":false,"showReleaseNote":true,"displayDefaultContainerMemoryGB":6,"broadenedEditPermission":false,"enableNotebookCommandMode":true,"disableS3TableImport":false,"deploymentMode":"production","useSpotForWorkers":true,"removePasswordInAccountSettings":false,"preferStartTerminatedCluster":false,"enableUserInviteWorkflow":true,"createTableConnectorOptionLinks":[{"url":"https://docs.databricks.com/_static/notebooks/redshift.html","displayName":"Amazon Redshift","workspaceFileName":"Amazon Redshift Example"},{"url":"https://docs.databricks.com/_static/notebooks/structured-streaming-kinesis.html","displayName":"Amazon Kinesis","workspaceFileName":"Amazon Kinesis Example"},{"url":"https://docs.databricks.com/_static/notebooks/data-import/jdbc.html","displayName":"JDBC","workspaceFileName":"JDBC Example"},{"url":"https://docs.databricks.com/_static/notebooks/cassandra.html","displayName":"Cassandra","workspaceFileName":"Cassandra Example"},{"url":"https://docs.databricks.com/_static/notebooks/structured-streaming-etl-kafka.html","displayName":"Kafka","workspaceFileName":"Kafka Example"},{"url":"https://docs.databricks.com/_static/notebooks/redis.html","displayName":"Redis","workspaceFileName":"Redis Example"},{"url":"https://docs.databricks.com/_static/notebooks/elasticsearch.html","displayName":"Elasticsearch","workspaceFileName":"Elasticsearch Example"}],"enableStaticNotebooks":true,"sandboxForUrlSandboxFrame":"allow-scripts allow-popups allow-popups-to-escape-sandbox allow-forms","enableCssTransitions":true,"serverlessEnableElasticDisk":true,"minClusterTagKeyLength":1,"showHomepageFeaturedLinks":true,"pricingURL":"https://databricks.com/product/pricing","enableClusterEdit":true,"enableClusterAclsConfig":false,"useTempS3UrlForTableUpload":false,"notifyLastLogin":false,"enableSshKeyUIByTier":false,"enableCreateClusterOnAttach":true,"defaultAutomatedPricePerDBU":0.2,"enableNotebookGitVersioning":true,"defaultMinWorkers":2,"files":"files/","feedbackEmail":"feedback@databricks.com","enableDriverLogsUI":true,"defaultMaxWorkers":8,"enableWorkspaceAclsConfig":false,"serverlessRunPythonAsLowPrivilegeUser":false,"dropzoneMaxFileSize":2047,"enableNewClustersList":true,"enableNewDashboardViews":true,"enableJobListPermissionFilter":false,"driverLog4jFilePrefix":"log4j","enableSingleSignOn":true,"enableMavenLibraries":true,"displayRowLimit":1000,"deltaProcessingAsyncEnabled":true,"enableSparkEnvironmentVariablesUI":false,"defaultSparkVersion":{"key":"3.5.x-scala2.11","displayName":"3.5 (includes Apache Spark 2.2.1, Scala 2.11)","packageLabel":"spark-image-edea2f4129c468cb4b9642796b9933911d5e3723e9a97553ff5b0fbb7121d114","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},"deprecatedEnableStructuredDataAcls":false,"enableCustomSpotPricing":false,"enableMountAclsConfig":false,"defaultAutoterminationMin":120,"useDevTierHomePage":true,"disableExportNotebook":false,"enableClusterClone":true,"enableNotebookLineNumbers":true,"enablePublishHub":false,"notebookHubUrl":"http://hub.dev.databricks.com/","showSqlEndpoints":false,"enableNotebookDatasetInfoView":true,"defaultTagKeys":{"CLUSTER_NAME":"ClusterName","VENDOR":"Vendor","CLUSTER_TYPE":"ResourceClass","CREATOR":"Creator","CLUSTER_ID":"ClusterId"},"enableClusterAclsByTier":false,"databricksDocsBaseUrl":"https://docs.databricks.com/","azurePortalLink":"https://portal.azure.com","cloud":"AWS","disallowAddingAdmins":true,"enableSparkConfUI":true,"featureTier":"DEVELOPER_BASIC_TIER","mavenCentralSearchEndpoint":"http://search.maven.org/solrsearch/select","defaultServerlessClusterModel":{"cluster_name":"","node_type_id":"i3.2xlarge","spark_version":"latest-stable-scala2.11","num_workers":null,"enable_jdbc_auto_start":true,"custom_tags":{"ResourceClass":"Serverless"},"autoscale":{"min_workers":2,"max_workers":20},"spark_conf":{"spark.databricks.cluster.profile":"serverless","spark.databricks.repl.allowedLanguages":"sql,python","spark.databricks.acl.enabled":"false","spark.databricks.acl.sqlOnly":"false"},"aws_attributes":{"ebs_volume_count":null,"availability":"ON_DEMAND","first_on_demand":1,"ebs_volume_type":null,"spot_bid_price_percent":100,"zone_id":"us-west-2c","ebs_volume_size":null},"autotermination_minutes":0,"enable_elastic_disk":false,"default_tags":{"Vendor":"Databricks","Creator":"marissaldouglas@gmail.com","ClusterName":null,"ClusterId":"<Generated after creation>"}},"enableOrgSwitcherUI":true,"bitbucketCloudBaseApiV2Url":"https://api.bitbucket.org/2.0","clustersLimit":1,"enableJdbcImport":true,"enableElasticDisk":false,"logfiles":"logfiles/","enableRelativeNotebookLinks":true,"enableMultiSelect":true,"homePageLogo":"login/databricks_logoTM_rgb_TM.svg","enableWebappSharding":true,"enableNotebookParamsEdit":true,"enableClusterDeltaUpdates":true,"enableSingleSignOnLogin":false,"separateTableForJobClusters":true,"ebsVolumeSizeLimitGB":{"GENERAL_PURPOSE_SSD":[100,4096],"THROUGHPUT_OPTIMIZED_HDD":[500,4096]},"enableMountAcls":false,"requireEmailUserName":true,"dbcFeedbackURL":"mailto:feedback@databricks.com","enableMountAclService":true,"enableSingleSignOnByTierForOrg":false,"showVersion":true,"serverlessClustersByDefault":false,"enableWorkspaceAcls":false,"maxClusterTagKeyLength":127,"gitHash":"","clusterTagReservedPrefixes":[],"tableAclsEnabledMap":{"spark.databricks.acl.dfAclsEnabled":"true"},"showWorkspaceFeaturedLinks":true,"signupUrl":"https://databricks.com/try-databricks","databricksDocsNotebookPathPrefix":"^https://docs\\.databricks\\.com/_static/notebooks/.+$","serverlessAttachEbsVolumesByDefault":false,"enableTokensConfig":false,"allowFeedbackForumAccess":true,"enableImportFromUrl":true,"allowDisplayHtmlByUrl":true,"enableTokens":false,"enableMiniClusters":true,"enableNewJobList":true,"enableDebugUI":false,"enableStreamingMetricsDashboard":true,"allowNonAdminUsers":true,"enableSingleSignOnByTier":false,"enableJobsRetryOnTimeout":true,"loginLogo":"/login/databricks_logoTM_rgb_TM.svg","useStandardTierUpgradeTooltips":true,"staticNotebookResourceUrl":"https://databricks-prod-cloudfront.cloud.databricks.com/static/785e573cb9325327d1468f16a431e6d7119df032dd9ffcc16d4a909725271125/","enableSpotClusterType":true,"enableSparkPackages":true,"checkAadUserInWorkspaceTenant":false,"dynamicSparkVersions":true,"useIframeForHtmlResult":false,"enableClusterTagsUIByTier":false,"enableNotebookHistoryUI":true,"addWhitespaceAfterLastNotebookCell":true,"enableClusterLoggingUI":true,"enableDatabaseDropdownInTableUI":true,"showDebugCounters":false,"enableInstanceProfilesUI":false,"enableFolderHtmlExport":true,"homepageFeaturedLinks":[{"linkURI":"https://docs.databricks.com/_static/notebooks/gentle-introduction-to-apache-spark.html","displayName":"Introduction to Apache Spark on Databricks","icon":"img/home/Python_icon.svg"},{"linkURI":"https://docs.databricks.com/_static/notebooks/databricks-for-data-scientists.html","displayName":"Databricks for Data Scientists","icon":"img/home/Scala_icon.svg"},{"linkURI":"https://docs.databricks.com/_static/notebooks/structured-streaming-python.html","displayName":"Introduction to Structured Streaming","icon":"img/home/Python_icon.svg"}],"enableClusterStart":false,"maxImportFileVersion":5,"enableEBSVolumesUIByTier":false,"singleSignOnComingSoon":false,"enableTableAclService":false,"removeSubCommandCodeWhenExport":true,"upgradeURL":"https://accounts.cloud.databricks.com/registration.html#login","maxAutoterminationMinutes":10000,"showResultsFromExternalSearchEngine":true,"autoterminateClustersByDefault":true,"notebookLoadingBackground":"#fff","sshContainerForwardedPort":2200,"enableServerAutoComplete":true,"enableStaticHtmlImport":true,"enableInstanceProfilesByTier":false,"showForgotPasswordLink":true,"defaultMemoryPerContainerMB":6000,"enablePresenceUI":true,"minAutoterminationMinutes":10,"accounts":true,"useOnDemandClustersByDefault":true,"useFramedStaticNotebooks":false,"enableNewProgressReportUI":true,"enableAutoCreateUserUI":true,"defaultCoresPerContainer":4,"showTerminationReason":true,"enableNewClustersGet":true,"showPricePerDBU":false,"showSqlProxyUI":true,"enableNotebookErrorHighlighting":true};</script>
<script>var __DATABRICKS_NOTEBOOK_MODEL = {"version":"NotebookV1","origId":3731405024398537,"name":"NLP_scala_Spark","language":"scala","commands":[{"version":"CommandV1","origId":661355323505165,"guid":"efc30530-f608-4f1e-bd09-496166c4af01","subtype":"command","commandType":"auto","position":0.25,"command":"import org.apache.spark.ml.feature.{StringIndexer, CountVectorizer, Tokenizer, StopWordsRemover, VectorAssembler, IDF}\nimport org.apache.spark.ml.{Pipeline, PipelineModel}\nimport org.apache.spark.ml.classification.LogisticRegression\nimport org.apache.spark.ml.evaluation.{MulticlassClassificationEvaluator, BinaryClassificationEvaluator}\nimport org.apache.spark.ml.tuning.{CrossValidator, ParamGridBuilder}\nimport org.apache.spark.sql.functions.{regexp_extract, regexp_replace}","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">import org.apache.spark.ml.feature.{StringIndexer, CountVectorizer, Tokenizer, StopWordsRemover, VectorAssembler, IDF}\nimport org.apache.spark.ml.{Pipeline, PipelineModel}\nimport org.apache.spark.ml.classification.LogisticRegression\nimport org.apache.spark.ml.evaluation.{MulticlassClassificationEvaluator, BinaryClassificationEvaluator}\nimport org.apache.spark.ml.tuning.{CrossValidator, ParamGridBuilder}\nimport org.apache.spark.sql.functions.{regexp_extract, regexp_replace}\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":"<div class=\"ansiout\">notebook:4: error: object BinaryClassifcationEvaluator is not a member of package org.apache.spark.ml.evaluation\nimport org.apache.spark.ml.evaluation.{MulticlassClassificationEvaluator, BinaryClassifcationEvaluator}\n       ^\n</div>","error":null,"workflows":[],"startTime":1512666353574,"submitTime":1512666353555,"finishTime":1512666353718,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"770efdd5-fdf4-47da-aa45-9943d2e704c2"},{"version":"CommandV1","origId":3731405024398540,"guid":"0d704619-e7a2-440e-83ad-dfb2217e1e5e","subtype":"command","commandType":"auto","position":0.5,"command":"var df = sqlContext\n  .read\n  .format(\"csv\")\n  .option(\"delimiter\", \"\\t\")\n  .option(\"header\", \"false\")\n  .option(\"inferSchema\", \"true\")\n  .load(\"/FileStore/tables/SMSSpamCollection.dms\")","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">df: org.apache.spark.sql.DataFrame = [_c0: string, _c1: string]\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[{"name":"df","typeStr":"org.apache.spark.sql.DataFrame","schema":{"type":"struct","fields":[{"name":"_c0","type":"string","nullable":true,"metadata":{}},{"name":"_c1","type":"string","nullable":true,"metadata":{}}]},"tableIdentifier":null}]},"errorSummary":"java.lang.ClassNotFoundException: Failed to find data source: .tsv. Please find packages at http://spark.apache.org/third-party-projects.html","error":"<div class=\"ansiout\">\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:595)\n\tat org.apache.spark.sql.execution.datasources.DataSource.providingClass$lzycompute(DataSource.scala:89)\n\tat org.apache.spark.sql.execution.datasources.DataSource.providingClass(DataSource.scala:89)\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:322)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:207)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:185)\n\tat linea8a3ab547d144c2495c77049498b188737.$read$$iw$$iw$$iw$$iw$$iw$$iw.&lt;init&gt;(command-3731405024398540:6)\n\tat linea8a3ab547d144c2495c77049498b188737.$read$$iw$$iw$$iw$$iw$$iw.&lt;init&gt;(command-3731405024398540:47)\n\tat linea8a3ab547d144c2495c77049498b188737.$read$$iw$$iw$$iw$$iw.&lt;init&gt;(command-3731405024398540:49)\n\tat linea8a3ab547d144c2495c77049498b188737.$read$$iw$$iw$$iw.&lt;init&gt;(command-3731405024398540:51)\n\tat linea8a3ab547d144c2495c77049498b188737.$read$$iw$$iw.&lt;init&gt;(command-3731405024398540:53)\n\tat linea8a3ab547d144c2495c77049498b188737.$read$$iw.&lt;init&gt;(command-3731405024398540:55)\n\tat linea8a3ab547d144c2495c77049498b188737.$read.&lt;init&gt;(command-3731405024398540:57)\n\tat linea8a3ab547d144c2495c77049498b188737.$read$.&lt;init&gt;(command-3731405024398540:61)\n\tat linea8a3ab547d144c2495c77049498b188737.$read$.&lt;clinit&gt;(command-3731405024398540)\n\tat linea8a3ab547d144c2495c77049498b188737.$eval$.$print$lzycompute(&lt;notebook&gt;:7)\n\tat linea8a3ab547d144c2495c77049498b188737.$eval$.$print(&lt;notebook&gt;:6)\n\tat linea8a3ab547d144c2495c77049498b188737.$eval.$print(&lt;notebook&gt;)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat scala.tools.nsc.interpreter.IMain$ReadEvalPrint.call(IMain.scala:786)\n\tat scala.tools.nsc.interpreter.IMain$Request.loadAndRun(IMain.scala:1047)\n\tat scala.tools.nsc.interpreter.IMain$WrappedRequest$$anonfun$loadAndRunReq$1.apply(IMain.scala:638)\n\tat scala.tools.nsc.interpreter.IMain$WrappedRequest$$anonfun$loadAndRunReq$1.apply(IMain.scala:637)\n\tat scala.reflect.internal.util.ScalaClassLoader$class.asContext(ScalaClassLoader.scala:31)\n\tat scala.reflect.internal.util.AbstractFileClassLoader.asContext(AbstractFileClassLoader.scala:19)\n\tat scala.tools.nsc.interpreter.IMain$WrappedRequest.loadAndRunReq(IMain.scala:637)\n\tat scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:569)\n\tat scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:565)\n\tat com.databricks.backend.daemon.driver.DriverILoop.execute(DriverILoop.scala:186)\n\tat com.databricks.backend.daemon.driver.ScalaDriverLocal$$anonfun$repl$1.apply$mcV$sp(ScalaDriverLocal.scala:182)\n\tat com.databricks.backend.daemon.driver.ScalaDriverLocal$$anonfun$repl$1.apply(ScalaDriverLocal.scala:182)\n\tat com.databricks.backend.daemon.driver.ScalaDriverLocal$$anonfun$repl$1.apply(ScalaDriverLocal.scala:182)\n\tat com.databricks.backend.daemon.driver.DriverLocal$TrapExitInternal$.trapExit(DriverLocal.scala:456)\n\tat com.databricks.backend.daemon.driver.DriverLocal$TrapExit$.apply(DriverLocal.scala:410)\n\tat com.databricks.backend.daemon.driver.ScalaDriverLocal.repl(ScalaDriverLocal.scala:182)\n\tat com.databricks.backend.daemon.driver.DriverLocal$$anonfun$execute$3.apply(DriverLocal.scala:234)\n\tat com.databricks.backend.daemon.driver.DriverLocal$$anonfun$execute$3.apply(DriverLocal.scala:215)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:188)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:183)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:39)\n\tat com.databricks.logging.UsageLogging$class.withAttributionTags(UsageLogging.scala:221)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:39)\n\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:215)\n\tat com.databricks.backend.daemon.driver.DriverWrapper$$anonfun$tryExecutingCommand$2.apply(DriverWrapper.scala:601)\n\tat com.databricks.backend.daemon.driver.DriverWrapper$$anonfun$tryExecutingCommand$2.apply(DriverWrapper.scala:601)\n\tat scala.util.Try$.apply(Try.scala:192)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:596)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.getCommandOutputAndError(DriverWrapper.scala:486)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:554)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:391)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:348)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:215)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.ClassNotFoundException: .tsv.DefaultSource\n\tat scala.reflect.internal.util.AbstractFileClassLoader.findClass(AbstractFileClassLoader.scala:62)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:424)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:357)\n\tat org.apache.spark.sql.execution.datasources.DataSource$$anonfun$25$$anonfun$apply$16.apply(DataSource.scala:579)\n\tat org.apache.spark.sql.execution.datasources.DataSource$$anonfun$25$$anonfun$apply$16.apply(DataSource.scala:579)\n\tat scala.util.Try$.apply(Try.scala:192)\n\tat org.apache.spark.sql.execution.datasources.DataSource$$anonfun$25.apply(DataSource.scala:579)\n\tat org.apache.spark.sql.execution.datasources.DataSource$$anonfun$25.apply(DataSource.scala:579)\n\tat scala.util.Try.orElse(Try.scala:84)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:579)\n\tat org.apache.spark.sql.execution.datasources.DataSource.providingClass$lzycompute(DataSource.scala:89)\n\tat org.apache.spark.sql.execution.datasources.DataSource.providingClass(DataSource.scala:89)\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:322)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:207)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:185)\n\tat linea8a3ab547d144c2495c77049498b188737.$read$$iw$$iw$$iw$$iw$$iw$$iw.&lt;init&gt;(command-3731405024398540:6)\n\tat linea8a3ab547d144c2495c77049498b188737.$read$$iw$$iw$$iw$$iw$$iw.&lt;init&gt;(command-3731405024398540:47)\n\tat linea8a3ab547d144c2495c77049498b188737.$read$$iw$$iw$$iw$$iw.&lt;init&gt;(command-3731405024398540:49)\n\tat linea8a3ab547d144c2495c77049498b188737.$read$$iw$$iw$$iw.&lt;init&gt;(command-3731405024398540:51)\n\tat linea8a3ab547d144c2495c77049498b188737.$read$$iw$$iw.&lt;init&gt;(command-3731405024398540:53)\n\tat linea8a3ab547d144c2495c77049498b188737.$read$$iw.&lt;init&gt;(command-3731405024398540:55)\n\tat linea8a3ab547d144c2495c77049498b188737.$read.&lt;init&gt;(command-3731405024398540:57)\n\tat linea8a3ab547d144c2495c77049498b188737.$read$.&lt;init&gt;(command-3731405024398540:61)\n\tat linea8a3ab547d144c2495c77049498b188737.$read$.&lt;clinit&gt;(command-3731405024398540)\n\tat linea8a3ab547d144c2495c77049498b188737.$eval$.$print$lzycompute(&lt;notebook&gt;:7)\n\tat linea8a3ab547d144c2495c77049498b188737.$eval$.$print(&lt;notebook&gt;:6)\n\tat linea8a3ab547d144c2495c77049498b188737.$eval.$print(&lt;notebook&gt;)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat scala.tools.nsc.interpreter.IMain$ReadEvalPrint.call(IMain.scala:786)\n\tat scala.tools.nsc.interpreter.IMain$Request.loadAndRun(IMain.scala:1047)\n\tat scala.tools.nsc.interpreter.IMain$WrappedRequest$$anonfun$loadAndRunReq$1.apply(IMain.scala:638)\n\tat scala.tools.nsc.interpreter.IMain$WrappedRequest$$anonfun$loadAndRunReq$1.apply(IMain.scala:637)\n\tat scala.reflect.internal.util.ScalaClassLoader$class.asContext(ScalaClassLoader.scala:31)\n\tat scala.reflect.internal.util.AbstractFileClassLoader.asContext(AbstractFileClassLoader.scala:19)\n\tat scala.tools.nsc.interpreter.IMain$WrappedRequest.loadAndRunReq(IMain.scala:637)\n\tat scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:569)\n\tat scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:565)\n\tat com.databricks.backend.daemon.driver.DriverILoop.execute(DriverILoop.scala:186)\n\tat com.databricks.backend.daemon.driver.ScalaDriverLocal$$anonfun$repl$1.apply$mcV$sp(ScalaDriverLocal.scala:182)\n\tat com.databricks.backend.daemon.driver.ScalaDriverLocal$$anonfun$repl$1.apply(ScalaDriverLocal.scala:182)\n\tat com.databricks.backend.daemon.driver.ScalaDriverLocal$$anonfun$repl$1.apply(ScalaDriverLocal.scala:182)\n\tat com.databricks.backend.daemon.driver.DriverLocal$TrapExitInternal$.trapExit(DriverLocal.scala:456)\n\tat com.databricks.backend.daemon.driver.DriverLocal$TrapExit$.apply(DriverLocal.scala:410)\n\tat com.databricks.backend.daemon.driver.ScalaDriverLocal.repl(ScalaDriverLocal.scala:182)\n\tat com.databricks.backend.daemon.driver.DriverLocal$$anonfun$execute$3.apply(DriverLocal.scala:234)\n\tat com.databricks.backend.daemon.driver.DriverLocal$$anonfun$execute$3.apply(DriverLocal.scala:215)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:188)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:183)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:39)\n\tat com.databricks.logging.UsageLogging$class.withAttributionTags(UsageLogging.scala:221)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:39)\n\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:215)\n\tat com.databricks.backend.daemon.driver.DriverWrapper$$anonfun$tryExecutingCommand$2.apply(DriverWrapper.scala:601)\n\tat com.databricks.backend.daemon.driver.DriverWrapper$$anonfun$tryExecutingCommand$2.apply(DriverWrapper.scala:601)\n\tat scala.util.Try$.apply(Try.scala:192)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:596)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.getCommandOutputAndError(DriverWrapper.scala:486)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:554)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:391)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:348)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:215)\n\tat java.lang.Thread.run(Thread.java:748)</div>","workflows":[],"startTime":1512659479744,"submitTime":1512659479716,"finishTime":1512659481078,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"358106ee-8de1-4f41-beaa-8669e53040d0"},{"version":"CommandV1","origId":661355323505193,"guid":"d3f5eabe-fbb3-4d7a-b109-29332b7a6cc5","subtype":"command","commandType":"auto","position":0.75,"command":"// using regex replace to see if big numbers have an effect because a lot of spam has a large coupon code, etc\ndf = df.withColumn(\"_c1\", regexp_replace($\"_c1\", \"\\\\b\\\\d(2,)\\\\b\", \"BIGNUMBER\"))\ndf = df.withColumn(\"_c1\", regexp_replace($\"_c1\", \"[$]\", \"CASHMONEY\"))","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">df: org.apache.spark.sql.DataFrame = [_c0: string, _c1: string]\ndf: org.apache.spark.sql.DataFrame = [_c0: string, _c1: string]\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1512667024219,"submitTime":1512667024197,"finishTime":1512667024535,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"2999f775-549f-4355-949a-90b118e1fbe0"},{"version":"CommandV1","origId":3731405024398538,"guid":"28a9d085-6364-4817-9f80-fac285d6e300","subtype":"command","commandType":"auto","position":1.0,"command":"df.show(5)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">+----+--------------------+\n| _c0|                 _c1|\n+----+--------------------+\n| ham|Go until jurong p...|\n| ham|Ok lar... Joking ...|\n|spam|Free entry in 2 a...|\n| ham|U dun say so earl...|\n| ham|Nah I don't think...|\n+----+--------------------+\nonly showing top 5 rows\n\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1512659562698,"submitTime":1512659562674,"finishTime":1512659563161,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"43a7dde3-0013-4bfb-919f-2aa3393e86cd"},{"version":"CommandV1","origId":661355323505164,"guid":"95a8361a-8096-4c50-aefb-fdaa015a8686","subtype":"command","commandType":"auto","position":2.0,"command":"val stringIndexer = new StringIndexer()\n  .setInputCol(\"_c0\")\n  .setOutputCol(\"label\")\n  .setHandleInvalid(\"keep\")","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">stringIndexer: org.apache.spark.ml.feature.StringIndexer = strIdx_ed7047ba0d73\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":"<div class=\"ansiout\">notebook:3: error: value setOuputCol is not a member of org.apache.spark.ml.feature.StringIndexer\npossible cause: maybe a semicolon is missing before `value setOuputCol'?\n  .setOuputCol(&quot;IndexedLabel&quot;)\n   ^\n</div>","error":null,"workflows":[],"startTime":1512667027719,"submitTime":1512667027693,"finishTime":1512667027896,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"0071c066-5efe-4041-9ce9-be683955641b"},{"version":"CommandV1","origId":661355323505166,"guid":"f7c2fdb6-4a6d-47e8-bd37-2e16ef683155","subtype":"command","commandType":"auto","position":3.0,"command":"// each row is a \"document\", each word is a \"term\"\nval tokenizer = new Tokenizer()\n  .setInputCol(\"_c1\")\n  .setOutputCol(\"tokens\")\n// regextokenizer would use custom regex pattern if wanted (ex: Crossfit project isolated crossfit terms)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">tokenizer: org.apache.spark.ml.feature.Tokenizer = tok_70c26b4f1a8d\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1512667029456,"submitTime":1512667029430,"finishTime":1512667029626,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"daa29454-c528-44a9-89a7-934596fc923c"},{"version":"CommandV1","origId":661355323505167,"guid":"1ac7d8e1-c9d4-40de-9d1b-1165ed9ece27","subtype":"command","commandType":"auto","position":4.0,"command":"tokenizer.transform(df).show(5)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">+----+--------------------+--------------------+\n| _c0|                 _c1|              tokens|\n+----+--------------------+--------------------+\n| ham|Go until jurong p...|[go, until, juron...|\n| ham|Ok lar... Joking ...|[ok, lar..., joki...|\n|spam|Free entry in 2 a...|[free, entry, in,...|\n| ham|U dun say so earl...|[u, dun, say, so,...|\n| ham|Nah I don't think...|[nah, i, don't, t...|\n+----+--------------------+--------------------+\nonly showing top 5 rows\n\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1512660597593,"submitTime":1512660597572,"finishTime":1512660598089,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"e92bc02d-0aa4-4e1e-bcaf-b5a59d08f38d"},{"version":"CommandV1","origId":661355323505168,"guid":"7011b262-2942-448d-b1c6-305bfa2b6e83","subtype":"command","commandType":"auto","position":5.0,"command":"val stopWords = new StopWordsRemover()\n  .setInputCol(tokenizer.getOutputCol)\n  .setOutputCol(\"filtered\")","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">stopWords: org.apache.spark.ml.feature.StopWordsRemover = stopWords_c3cb941f980c\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1512667032962,"submitTime":1512667032936,"finishTime":1512667033142,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"dc39f093-de47-4b0e-8fe4-ae8aa8c2f172"},{"version":"CommandV1","origId":661355323505169,"guid":"0cbae62a-b3ac-4957-b4bc-5361ea4cf6d7","subtype":"command","commandType":"auto","position":6.0,"command":"stopWords.transform(tokenizer.transform(df)).show(5)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">+----+--------------------+--------------------+--------------------+\n| _c0|                 _c1|              tokens|            filtered|\n+----+--------------------+--------------------+--------------------+\n| ham|Go until jurong p...|[go, until, juron...|[go, jurong, poin...|\n| ham|Ok lar... Joking ...|[ok, lar..., joki...|[ok, lar..., joki...|\n|spam|Free entry in 2 a...|[free, entry, in,...|[free, entry, 2, ...|\n| ham|U dun say so earl...|[u, dun, say, so,...|[u, dun, say, ear...|\n| ham|Nah I don't think...|[nah, i, don't, t...|[nah, think, goes...|\n+----+--------------------+--------------------+--------------------+\nonly showing top 5 rows\n\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1512666692462,"submitTime":1512666692439,"finishTime":1512666692936,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"9f5a1d7b-6d1d-43a1-a151-7372b72331d6"},{"version":"CommandV1","origId":661355323505171,"guid":"cbe6f50a-dd08-498f-80a4-e768832f2c49","subtype":"command","commandType":"auto","position":7.0,"command":"val countVectorizer = new CountVectorizer()\n  .setInputCol(stopWords.getOutputCol)\n  .setOutputCol(\"vectorized\")","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">countVectorizer: org.apache.spark.ml.feature.CountVectorizer = cntVec_25f4e29735bd\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1512667037228,"submitTime":1512667037202,"finishTime":1512667037408,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"d5c528af-cceb-4339-b00a-c799228b53f5"},{"version":"CommandV1","origId":661355323505191,"guid":"09bf76e5-6b7e-4a68-9f30-011cfd7cadea","subtype":"command","commandType":"auto","position":7.25,"command":"val idf = new IDF()\n  .setInputCol(countVectorizer.getOutputCol)\n  .setOutputCol(\"idf\")","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">idf: org.apache.spark.ml.feature.IDF = idf_40b9ca4d9275\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":"<div class=\"ansiout\">&lt;console&gt;:7: error: unclosed string literal\n  .setOutputCol(&quot;idf)\n                ^\n</div>","error":null,"workflows":[],"startTime":1512667038328,"submitTime":1512667038302,"finishTime":1512667038510,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"86f63d7b-91e0-42da-93c2-0b859035007e"},{"version":"CommandV1","origId":661355323505192,"guid":"d5cedcd7-eb3f-4b6a-9ce6-9c40bc364189","subtype":"command","commandType":"auto","position":7.375,"command":"val assembler = new VectorAssembler()\n  .setInputCols(Array(idf.getOutputCol))\n  .setOutputCol(\"features\")\n\nvar lr = new LogisticRegression()","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">assembler: org.apache.spark.ml.feature.VectorAssembler = vecAssembler_257b1355635d\nlr: org.apache.spark.ml.classification.LogisticRegression = logreg_7fe5b1f5b92c\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1512667040270,"submitTime":1512667040245,"finishTime":1512667040519,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"13622da7-80d2-4662-87ad-cd5c99a06836"},{"version":"CommandV1","origId":661355323505174,"guid":"36b2a61a-e14c-4d98-b1db-a39925720541","subtype":"command","commandType":"auto","position":7.5,"command":"val pipe = new Pipeline()\n  .setStages(Array(stringIndexer, tokenizer, stopWords, countVectorizer, idf, assembler, lr))","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">pipe: org.apache.spark.ml.Pipeline = pipeline_4309a1542a13\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":"<div class=\"ansiout\">notebook:2: error: type mismatch;\n found   : String\n required: Array[String]\n  .setInputCols(countVectorizer.getOutputCol)\n                                ^\n</div>","error":null,"workflows":[],"startTime":1512667042814,"submitTime":1512667042789,"finishTime":1512667043113,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"088d6960-370d-4ad4-a79a-4ad610c4417a"},{"version":"CommandV1","origId":661355323505182,"guid":"bf38eca9-e77e-4290-b8a8-5e23a4ae4798","subtype":"command","commandType":"auto","position":8.25,"command":"val evaluator = new MulticlassClassificationEvaluator()\n  .setMetricName(\"accuracy\")","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">evaluator: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_dd64b8db1ddd\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1512667043916,"submitTime":1512667043890,"finishTime":1512667044087,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"da82ab69-8cb3-4901-89f4-945625be5d0e"},{"version":"CommandV1","origId":661355323505183,"guid":"3a180e92-b98d-4059-9e04-6a2d0c7f94a6","subtype":"command","commandType":"auto","position":8.625,"command":"val Array(train, test) = df.randomSplit(Array(0.8,0.2),2)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">train: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [_c0: string, _c1: string]\ntest: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [_c0: string, _c1: string]\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[{"name":"train","typeStr":"org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]","schema":{"type":"struct","fields":[{"name":"_c0","type":"string","nullable":true,"metadata":{}},{"name":"_c1","type":"string","nullable":true,"metadata":{}}]},"tableIdentifier":null},{"name":"test","typeStr":"org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]","schema":{"type":"struct","fields":[{"name":"_c0","type":"string","nullable":true,"metadata":{}},{"name":"_c1","type":"string","nullable":true,"metadata":{}}]},"tableIdentifier":null}]},"errorSummary":null,"error":null,"workflows":[],"startTime":1512667045911,"submitTime":1512667045885,"finishTime":1512667046492,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"1259a79e-837a-4c2f-ab41-274db51a936d"},{"version":"CommandV1","origId":661355323505173,"guid":"ec59b76f-913d-4b24-8314-12d9125a8fd6","subtype":"command","commandType":"auto","position":9.0,"command":"// val pipeModel = pipe.fit(train)\n// val predictions = pipeModel.transform(test)\n// evaluator.evaluate(predictions)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">pipeModel: org.apache.spark.ml.PipelineModel = pipeline_4203955ecfea\npredictions: org.apache.spark.sql.DataFrame = [_c0: string, _c1: string ... 8 more fields]\nres20: Double = 0.9637058261700095\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":"<div class=\"ansiout\">notebook:1: error: type mismatch;\n found   : (Double, Double)\n required: Array[Double]\nval Array(train, test) = df.randomSplit((0.8,0.2),2)\n                                        ^\n</div>","error":null,"workflows":[],"startTime":1512664210293,"submitTime":1512664210273,"finishTime":1512664216238,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"31911e4e-22f7-4b41-b596-779f32c5ed0d"},{"version":"CommandV1","origId":661355323505178,"guid":"41701081-53a9-4bb7-a2c0-cdd883442537","subtype":"command","commandType":"auto","position":13.0,"command":"val paramGrid = new ParamGridBuilder()\n  .addGrid(countVectorizer.vocabSize, Array(1000,2000))\n  .build()","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">paramGrid: Array[org.apache.spark.ml.param.ParamMap] =\nArray({\n\tcntVec_25f4e29735bd-vocabSize: 1000\n}, {\n\tcntVec_25f4e29735bd-vocabSize: 2000\n})\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1512667051168,"submitTime":1512667051142,"finishTime":1512667051394,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"708c9736-db56-4fe3-959c-d93d99d83311"},{"version":"CommandV1","origId":661355323505179,"guid":"d5a092bd-6a7f-4f06-abb1-733310d6d195","subtype":"command","commandType":"auto","position":14.0,"command":"var cv = new CrossValidator()\n  .setEstimator(pipe)\n  .setEstimatorParamMaps(paramGrid)\n  .setEvaluator(evaluator)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">cv: org.apache.spark.ml.tuning.CrossValidator = cv_d2cc15e52c08\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":"<div class=\"ansiout\">notebook:3: error: not found: value paramGrid\n  .setEstimatorParamMaps(paramGrid)\n                         ^\n</div>","error":null,"workflows":[],"startTime":1512667052310,"submitTime":1512667052284,"finishTime":1512667052501,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"2f6a9c9d-a455-4d5e-b1e7-334f841895aa"},{"version":"CommandV1","origId":661355323505185,"guid":"fdd8aef1-6e6c-4d0f-96d7-27732a325533","subtype":"command","commandType":"auto","position":16.0,"command":"// BASELINE\ndf.filter(\"_c0 = 'ham'\").count()/df.select(\"_c0\").count().toDouble\n// the toDouble was necessary because it was outputting an int which rounded down to zero","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">res54: Double = 0.8659849300322928\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":"org.apache.spark.sql.catalyst.parser.ParseException: ","error":"<div class=\"ansiout\">extraneous input ''' expecting {'(', 'SELECT', 'FROM', 'ADD', 'AS', 'ALL', 'DISTINCT', 'WHERE', 'GROUP', 'BY', 'GROUPING', 'SETS', 'CUBE', 'ROLLUP', 'ORDER', 'HAVING', 'LIMIT', 'AT', 'OR', 'AND', 'IN', NOT, 'NO', 'EXISTS', 'BETWEEN', 'LIKE', RLIKE, 'IS', 'NULL', 'TRUE', 'FALSE', 'NULLS', 'ASC', 'DESC', 'FOR', 'INTERVAL', 'CASE', 'WHEN', 'THEN', 'ELSE', 'END', 'JOIN', 'CROSS', 'OUTER', 'INNER', 'LEFT', 'SEMI', 'RIGHT', 'FULL', 'NATURAL', 'ON', 'LATERAL', 'WINDOW', 'OVER', 'PARTITION', 'RANGE', 'ROWS', 'UNBOUNDED', 'PRECEDING', 'FOLLOWING', 'CURRENT', 'FIRST', 'AFTER', 'LAST', 'ROW', 'WITH', 'VALUES', 'CREATE', 'TABLE', 'DIRECTORY', 'VIEW', 'REPLACE', 'INSERT', 'DELETE', 'INTO', 'DESCRIBE', 'EXPLAIN', 'FORMAT', 'LOGICAL', 'CODEGEN', 'COST', 'CAST', 'SHOW', 'TABLES', 'COLUMNS', 'COLUMN', 'USE', 'PARTITIONS', 'FUNCTIONS', 'DROP', 'UNION', 'EXCEPT', 'MINUS', 'INTERSECT', 'TO', 'TABLESAMPLE', 'STRATIFY', 'ALTER', 'RENAME', 'ARRAY', 'MAP', 'STRUCT', 'COMMENT', 'SET', 'RESET', 'DATA', 'START', 'TRANSACTION', 'COMMIT', 'ROLLBACK', 'MACRO', 'IGNORE', 'MERGE', 'MATCHED', 'UPDATE', 'IF', '+', '-', '*', 'DIV', '~', 'PERCENT', 'BUCKET', 'OUT', 'OF', 'SORT', 'CLUSTER', 'DISTRIBUTE', 'OVERWRITE', 'TRANSFORM', 'REDUCE', 'USING', 'SERDE', 'SERDEPROPERTIES', 'RECORDREADER', 'RECORDWRITER', 'DELIMITED', 'FIELDS', 'TERMINATED', 'COLLECTION', 'ITEMS', 'KEYS', 'ESCAPED', 'LINES', 'SEPARATED', 'FUNCTION', 'EXTENDED', 'REFRESH', 'CLEAR', 'CACHE', 'UNCACHE', 'LAZY', 'FORMATTED', 'GLOBAL', TEMPORARY, 'OPTIONS', 'UNSET', 'TBLPROPERTIES', 'DBPROPERTIES', 'BUCKETS', 'SKEWED', 'STORED', 'DIRECTORIES', 'LOCATION', 'EXCHANGE', 'ARCHIVE', 'UNARCHIVE', 'FILEFORMAT', 'TOUCH', 'COMPACT', 'CONCATENATE', 'CHANGE', 'CASCADE', 'RESTRICT', 'CLUSTERED', 'SORTED', 'PURGE', 'INPUTFORMAT', 'OUTPUTFORMAT', DATABASE, DATABASES, 'DFS', 'TRUNCATE', 'ANALYZE', 'COMPUTE', 'LIST', 'STATISTICS', 'PARTITIONED', 'EXTERNAL', 'DEFINED', 'REVOKE', 'GRANT', 'LOCK', 'UNLOCK', 'MSCK', 'REPAIR', 'RECOVER', 'EXPORT', 'IMPORT', 'LOAD', 'ROLE', 'ROLES', 'COMPACTIONS', 'PRINCIPALS', 'TRANSACTIONS', 'INDEX', 'INDEXES', 'LOCKS', 'OPTION', 'ANTI', 'LOCAL', 'INPATH', 'CURRENT_DATE', 'CURRENT_TIMESTAMP', 'OPTIMIZE', STRING, BIGINT_LITERAL, SMALLINT_LITERAL, TINYINT_LITERAL, INTEGER_VALUE, DECIMAL_VALUE, DOUBLE_LITERAL, BIGDECIMAL_LITERAL, IDENTIFIER, BACKQUOTED_IDENTIFIER}(line 1, pos 6)\n\n== SQL ==\n_c0 = 'ham\n------^^^\n\n\tat org.apache.spark.sql.catalyst.parser.ParseException.withCommand(ParseDriver.scala:235)\n\tat org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parse(ParseDriver.scala:116)\n\tat org.apache.spark.sql.execution.SparkSqlParser.parse(SparkSqlParser.scala:51)\n\tat org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parseExpression(ParseDriver.scala:45)\n\tat com.databricks.sql.parser.DatabricksSqlParser.parseExpression(DatabricksSqlParser.scala:35)\n\tat org.apache.spark.sql.Dataset.filter(Dataset.scala:1321)\n\tat linea8a3ab547d144c2495c77049498b1887434.$read$$iw$$iw$$iw$$iw$$iw$$iw.&lt;init&gt;(command-661355323505185:1)\n\tat linea8a3ab547d144c2495c77049498b1887434.$read$$iw$$iw$$iw$$iw$$iw.&lt;init&gt;(command-661355323505185:78)\n\tat linea8a3ab547d144c2495c77049498b1887434.$read$$iw$$iw$$iw$$iw.&lt;init&gt;(command-661355323505185:80)\n\tat linea8a3ab547d144c2495c77049498b1887434.$read$$iw$$iw$$iw.&lt;init&gt;(command-661355323505185:82)\n\tat linea8a3ab547d144c2495c77049498b1887434.$read$$iw$$iw.&lt;init&gt;(command-661355323505185:84)\n\tat linea8a3ab547d144c2495c77049498b1887434.$read$$iw.&lt;init&gt;(command-661355323505185:86)\n\tat linea8a3ab547d144c2495c77049498b1887434.$read.&lt;init&gt;(command-661355323505185:88)\n\tat linea8a3ab547d144c2495c77049498b1887434.$read$.&lt;init&gt;(command-661355323505185:92)\n\tat linea8a3ab547d144c2495c77049498b1887434.$read$.&lt;clinit&gt;(command-661355323505185)\n\tat linea8a3ab547d144c2495c77049498b1887434.$eval$.$print$lzycompute(&lt;notebook&gt;:7)\n\tat linea8a3ab547d144c2495c77049498b1887434.$eval$.$print(&lt;notebook&gt;:6)\n\tat linea8a3ab547d144c2495c77049498b1887434.$eval.$print(&lt;notebook&gt;)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat scala.tools.nsc.interpreter.IMain$ReadEvalPrint.call(IMain.scala:786)\n\tat scala.tools.nsc.interpreter.IMain$Request.loadAndRun(IMain.scala:1047)\n\tat scala.tools.nsc.interpreter.IMain$WrappedRequest$$anonfun$loadAndRunReq$1.apply(IMain.scala:638)\n\tat scala.tools.nsc.interpreter.IMain$WrappedRequest$$anonfun$loadAndRunReq$1.apply(IMain.scala:637)\n\tat scala.reflect.internal.util.ScalaClassLoader$class.asContext(ScalaClassLoader.scala:31)\n\tat scala.reflect.internal.util.AbstractFileClassLoader.asContext(AbstractFileClassLoader.scala:19)\n\tat scala.tools.nsc.interpreter.IMain$WrappedRequest.loadAndRunReq(IMain.scala:637)\n\tat scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:569)\n\tat scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:565)\n\tat com.databricks.backend.daemon.driver.DriverILoop.execute(DriverILoop.scala:186)\n\tat com.databricks.backend.daemon.driver.ScalaDriverLocal$$anonfun$repl$1.apply$mcV$sp(ScalaDriverLocal.scala:182)\n\tat com.databricks.backend.daemon.driver.ScalaDriverLocal$$anonfun$repl$1.apply(ScalaDriverLocal.scala:182)\n\tat com.databricks.backend.daemon.driver.ScalaDriverLocal$$anonfun$repl$1.apply(ScalaDriverLocal.scala:182)\n\tat com.databricks.backend.daemon.driver.DriverLocal$TrapExitInternal$.trapExit(DriverLocal.scala:456)\n\tat com.databricks.backend.daemon.driver.DriverLocal$TrapExit$.apply(DriverLocal.scala:410)\n\tat com.databricks.backend.daemon.driver.ScalaDriverLocal.repl(ScalaDriverLocal.scala:182)\n\tat com.databricks.backend.daemon.driver.DriverLocal$$anonfun$execute$3.apply(DriverLocal.scala:234)\n\tat com.databricks.backend.daemon.driver.DriverLocal$$anonfun$execute$3.apply(DriverLocal.scala:215)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:188)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:183)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:39)\n\tat com.databricks.logging.UsageLogging$class.withAttributionTags(UsageLogging.scala:221)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:39)\n\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:215)\n\tat com.databricks.backend.daemon.driver.DriverWrapper$$anonfun$tryExecutingCommand$2.apply(DriverWrapper.scala:601)\n\tat com.databricks.backend.daemon.driver.DriverWrapper$$anonfun$tryExecutingCommand$2.apply(DriverWrapper.scala:601)\n\tat scala.util.Try$.apply(Try.scala:192)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:596)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.getCommandOutputAndError(DriverWrapper.scala:486)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:554)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:391)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:348)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:215)\n\tat java.lang.Thread.run(Thread.java:748)</div>","workflows":[],"startTime":1512666665921,"submitTime":1512666665896,"finishTime":1512666667472,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"e003c209-39fa-4ff0-9e29-c760040d8465"},{"version":"CommandV1","origId":661355323505187,"guid":"6ed142b4-c9c8-4333-8376-7a11aead1933","subtype":"command","commandType":"auto","position":18.0,"command":"val cvModel = cv.fit(train)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">cvModel: org.apache.spark.ml.tuning.CrossValidatorModel = cv_d2cc15e52c08\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":"java.lang.IllegalArgumentException: Field \"new\" does not exist.","error":"<div class=\"ansiout\">\tat org.apache.spark.sql.types.StructType$$anonfun$apply$1.apply(StructType.scala:267)\n\tat org.apache.spark.sql.types.StructType$$anonfun$apply$1.apply(StructType.scala:267)\n\tat scala.collection.MapLike$class.getOrElse(MapLike.scala:128)\n\tat scala.collection.AbstractMap.getOrElse(Map.scala:59)\n\tat org.apache.spark.sql.types.StructType.apply(StructType.scala:266)\n\tat org.apache.spark.ml.util.SchemaUtils$.checkColumnTypes(SchemaUtils.scala:56)\n\tat org.apache.spark.ml.feature.CountVectorizerParams$class.validateAndTransformSchema(CountVectorizer.scala:75)\n\tat org.apache.spark.ml.feature.CountVectorizer.validateAndTransformSchema(CountVectorizer.scala:123)\n\tat org.apache.spark.ml.feature.CountVectorizer.transformSchema(CountVectorizer.scala:188)\n\tat org.apache.spark.ml.Pipeline$$anonfun$transformSchema$4.apply(Pipeline.scala:184)\n\tat org.apache.spark.ml.Pipeline$$anonfun$transformSchema$4.apply(Pipeline.scala:184)\n\tat scala.collection.IndexedSeqOptimized$class.foldl(IndexedSeqOptimized.scala:57)\n\tat scala.collection.IndexedSeqOptimized$class.foldLeft(IndexedSeqOptimized.scala:66)\n\tat scala.collection.mutable.ArrayOps$ofRef.foldLeft(ArrayOps.scala:186)\n\tat org.apache.spark.ml.Pipeline.transformSchema(Pipeline.scala:184)\n\tat org.apache.spark.ml.tuning.ValidatorParams$$anonfun$transformSchemaImpl$2.apply(ValidatorParams.scala:75)\n\tat org.apache.spark.ml.tuning.ValidatorParams$$anonfun$transformSchemaImpl$2.apply(ValidatorParams.scala:74)\n\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)\n\tat org.apache.spark.ml.tuning.ValidatorParams$class.transformSchemaImpl(ValidatorParams.scala:74)\n\tat org.apache.spark.ml.tuning.CrossValidator.transformSchemaImpl(CrossValidator.scala:65)\n\tat org.apache.spark.ml.tuning.CrossValidator.transformSchema(CrossValidator.scala:140)\n\tat org.apache.spark.ml.PipelineStage.transformSchema(Pipeline.scala:74)\n\tat org.apache.spark.ml.tuning.CrossValidator.fit(CrossValidator.scala:97)\n\tat linea8a3ab547d144c2495c77049498b1887510.$read$$iw$$iw$$iw$$iw$$iw$$iw.&lt;init&gt;(command-661355323505187:1)\n\tat linea8a3ab547d144c2495c77049498b1887510.$read$$iw$$iw$$iw$$iw$$iw.&lt;init&gt;(command-661355323505187:89)\n\tat linea8a3ab547d144c2495c77049498b1887510.$read$$iw$$iw$$iw$$iw.&lt;init&gt;(command-661355323505187:91)\n\tat linea8a3ab547d144c2495c77049498b1887510.$read$$iw$$iw$$iw.&lt;init&gt;(command-661355323505187:93)\n\tat linea8a3ab547d144c2495c77049498b1887510.$read$$iw$$iw.&lt;init&gt;(command-661355323505187:95)\n\tat linea8a3ab547d144c2495c77049498b1887510.$read$$iw.&lt;init&gt;(command-661355323505187:97)\n\tat linea8a3ab547d144c2495c77049498b1887510.$read.&lt;init&gt;(command-661355323505187:99)\n\tat linea8a3ab547d144c2495c77049498b1887510.$read$.&lt;init&gt;(command-661355323505187:103)\n\tat linea8a3ab547d144c2495c77049498b1887510.$read$.&lt;clinit&gt;(command-661355323505187)\n\tat linea8a3ab547d144c2495c77049498b1887510.$eval$.$print$lzycompute(&lt;notebook&gt;:7)\n\tat linea8a3ab547d144c2495c77049498b1887510.$eval$.$print(&lt;notebook&gt;:6)\n\tat linea8a3ab547d144c2495c77049498b1887510.$eval.$print(&lt;notebook&gt;)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat scala.tools.nsc.interpreter.IMain$ReadEvalPrint.call(IMain.scala:786)\n\tat scala.tools.nsc.interpreter.IMain$Request.loadAndRun(IMain.scala:1047)\n\tat scala.tools.nsc.interpreter.IMain$WrappedRequest$$anonfun$loadAndRunReq$1.apply(IMain.scala:638)\n\tat scala.tools.nsc.interpreter.IMain$WrappedRequest$$anonfun$loadAndRunReq$1.apply(IMain.scala:637)\n\tat scala.reflect.internal.util.ScalaClassLoader$class.asContext(ScalaClassLoader.scala:31)\n\tat scala.reflect.internal.util.AbstractFileClassLoader.asContext(AbstractFileClassLoader.scala:19)\n\tat scala.tools.nsc.interpreter.IMain$WrappedRequest.loadAndRunReq(IMain.scala:637)\n\tat scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:569)\n\tat scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:565)\n\tat com.databricks.backend.daemon.driver.DriverILoop.execute(DriverILoop.scala:186)\n\tat com.databricks.backend.daemon.driver.ScalaDriverLocal$$anonfun$repl$1.apply$mcV$sp(ScalaDriverLocal.scala:182)\n\tat com.databricks.backend.daemon.driver.ScalaDriverLocal$$anonfun$repl$1.apply(ScalaDriverLocal.scala:182)\n\tat com.databricks.backend.daemon.driver.ScalaDriverLocal$$anonfun$repl$1.apply(ScalaDriverLocal.scala:182)\n\tat com.databricks.backend.daemon.driver.DriverLocal$TrapExitInternal$.trapExit(DriverLocal.scala:456)\n\tat com.databricks.backend.daemon.driver.DriverLocal$TrapExit$.apply(DriverLocal.scala:410)\n\tat com.databricks.backend.daemon.driver.ScalaDriverLocal.repl(ScalaDriverLocal.scala:182)\n\tat com.databricks.backend.daemon.driver.DriverLocal$$anonfun$execute$3.apply(DriverLocal.scala:234)\n\tat com.databricks.backend.daemon.driver.DriverLocal$$anonfun$execute$3.apply(DriverLocal.scala:215)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:188)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:183)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:39)\n\tat com.databricks.logging.UsageLogging$class.withAttributionTags(UsageLogging.scala:221)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:39)\n\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:215)\n\tat com.databricks.backend.daemon.driver.DriverWrapper$$anonfun$tryExecutingCommand$2.apply(DriverWrapper.scala:601)\n\tat com.databricks.backend.daemon.driver.DriverWrapper$$anonfun$tryExecutingCommand$2.apply(DriverWrapper.scala:601)\n\tat scala.util.Try$.apply(Try.scala:192)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:596)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.getCommandOutputAndError(DriverWrapper.scala:486)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:554)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:391)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:348)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:215)\n\tat java.lang.Thread.run(Thread.java:748)</div>","workflows":[],"startTime":1512667055471,"submitTime":1512667055445,"finishTime":1512667083528,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"96e9d9c1-d0d0-462e-b074-ab001c47cd49"},{"version":"CommandV1","origId":661355323505189,"guid":"2cc2150e-0f5a-4399-b1c2-c0596d773b5e","subtype":"command","commandType":"auto","position":18.5,"command":"evaluator.evaluate(cvModel.transform(test))","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">res57: Double = 0.9579751671442216\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1512666744304,"submitTime":1512666744280,"finishTime":1512666745343,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"350e5169-d292-45eb-af38-dbe5fae67d73"}],"dashboards":[],"guid":"2b3e7f82-7d1a-4de3-8ea3-5e3399675664","globalVars":{},"iPythonMetadata":null,"inputWidgets":{}};</script>
<script
 src="https://databricks-prod-cloudfront.cloud.databricks.com/static/785e573cb9325327d1468f16a431e6d7119df032dd9ffcc16d4a909725271125/js/notebook-main.js"
 onerror="window.mainJsLoadError = true;"></script>
</head>
<body>
  <script>
if (window.mainJsLoadError) {
  var u = 'https://databricks-prod-cloudfront.cloud.databricks.com/static/785e573cb9325327d1468f16a431e6d7119df032dd9ffcc16d4a909725271125/js/notebook-main.js';
  var b = document.getElementsByTagName('body')[0];
  var c = document.createElement('div');
  c.innerHTML = ('<h1>Network Error</h1>' +
    '<p><b>Please check your network connection and try again.</b></p>' +
    '<p>Could not load a required resource: ' + u + '</p>');
  c.style.margin = '30px';
  c.style.padding = '20px 50px';
  c.style.backgroundColor = '#f5f5f5';
  c.style.borderRadius = '5px';
  b.appendChild(c);
}
</script>
</body>
</html>
